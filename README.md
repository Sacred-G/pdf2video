<div align="center">

# ğŸ¬ PDF2Video

**Transform PDFs into cinematic, AI-narrated videos â€” not slideshows.**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Next.js](https://img.shields.io/badge/Next.js-15-000000?logo=next.js&logoColor=white)](https://nextjs.org)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17-4169E1?logo=postgresql&logoColor=white)](https://postgresql.org)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--5.2-412991?logo=openai&logoColor=white)](https://openai.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Upload a PDF â†’ AI writes a documentary-style script â†’ generates HD voiceover â†’ classifies every image â†’ composes a polished video with cinematic effects.

[Getting Started](#-getting-started) Â· [Features](#-features) Â· [Architecture](#-architecture) Â· [API Costs](#-api-cost-estimates)

</div>

---

## ğŸ¥ What It Does

PDF2Video takes any PDF document and produces a professional narrated video:

1. **Extracts** text and images from your PDF (PyMuPDF + pdfplumber)
2. **Classifies** every image using AI vision â€” charts, diagrams, tables, photos, logos
3. **Writes** a documentary-style narration script (GPT-5.2 Responses API)
4. **Generates** HD voiceover (OpenAI TTS with 6 voice options)
5. **Creates** atmospheric AI backgrounds for scenes that need them (gpt-image-1)
6. **Composes** a cinematic video with Ken Burns effects, smart layouts, transitions, and overlays
7. **Exports** with GPU acceleration (NVENC) or automatic CPU fallback

All orchestrated through a modern web UI with real-time progress tracking.

---

## âœ¨ Features

### AI Pipeline
- **Smart Image Classification** â€” AI vision categorizes every image (chart, diagram, table, photo, logo, decorative) for optimal composition
- **Structured Script Generation** â€” GPT-5.2 with structured output produces scene-by-scene narration with layout hints
- **HD Voiceover** â€” OpenAI TTS with 6 voice options for natural narration
- **AI Backgrounds** â€” gpt-image-1 generates atmospheric visuals for scenes that need them

### Video Composition
- **Multi-Layout Engine** â€” Split-screen, picture-in-picture, carousel, and single layouts chosen per-scene by AI
- **Ken Burns Effects** â€” Cinematic pan/zoom with per-image parameters based on content type
- **Smart Overlays** â€” Lower-third text, callout boxes for charts, logo watermarks
- **Crossfade Transitions** â€” Smooth scene-to-scene transitions with color grading and vignettes
- **Background Music** â€” Optional music track mixed under narration at configurable volume

### Full-Stack Web App
- **Next.js 15 Frontend** â€” React 19, shadcn/ui, Tailwind CSS 4, dark/light theme
- **FastAPI Backend** â€” Async Python with PostgreSQL, JWT auth, file uploads
- **Real-Time Progress** â€” SSE streaming shows live pipeline status in the browser
- **Job Queue** â€” Background workers with async task dispatch
- **Drag-and-Drop Upload** â€” PDF, image, and music upload with progress bars
- **Video Library** â€” Browse, stream, and download generated videos

### Performance
- **GPU-Accelerated Export** â€” NVIDIA NVENC encoding with automatic CPU (libx264) fallback
- **Auto-Tuned Workers** â€” Thread pool sized to your hardware
- **Async Everything** â€” Non-blocking I/O from database to file storage

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.11+**
- **Node.js 18+**
- **PostgreSQL 15+**
- **FFmpeg** (with NVENC support for GPU encoding, or CPU-only is fine)
- **OpenAI API Key** with access to GPT, TTS, and image generation

### 1. Clone

```bash
git clone https://github.com/Sacred-G/pdf2video.git
cd pdf2video
```

### 2. Backend Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### 3. Database Setup

```bash
# Create PostgreSQL database
createdb pdf2video
# Or with psql:
# CREATE USER pdf2video WITH PASSWORD 'password';
# CREATE DATABASE pdf2video OWNER pdf2video;
```

Update `DATABASE_URL` in `.env` if your credentials differ from the defaults.

### 4. Frontend Setup

```bash
cd frontend
npm install
cp .env.local.example .env.local
cd ..
```

### 5. Run

```bash
# Terminal 1 â€” Backend (from project root)
source .venv/bin/activate
python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload

# Terminal 2 â€” Frontend
cd frontend
npm run dev
```

Open **http://localhost:3000** â€” register an account, upload a PDF, and generate your first video.

---

## ğŸ™ï¸ Voice Options

| Voice | Style | Best For |
|-------|-------|----------|
| **onyx** | Deep, authoritative | Documentaries, training, reports |
| **alloy** | Balanced, versatile | General purpose |
| **echo** | Warm, conversational | Friendly explainers |
| **fable** | Expressive, dynamic | Storytelling |
| **nova** | Bright, engaging | Upbeat content |
| **shimmer** | Soft, clear | Gentle presentations |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BROWSER (Next.js 15)                       â”‚
â”‚  Dashboard Â· Create Job Â· Job Progress Â· Video Library       â”‚
â”‚  React 19 Â· shadcn/ui Â· Tailwind Â· Zustand Â· SSE            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ REST + SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FASTAPI BACKEND                            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Auth    â”‚  â”‚ Jobs API â”‚  â”‚ Uploads â”‚  â”‚ Video Stream â”‚  â”‚
â”‚  â”‚ (JWT)   â”‚  â”‚ (CRUD)   â”‚  â”‚ (Files) â”‚  â”‚ (Range)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚            â”‚             â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Background Worker (ThreadPool)                â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚  PDF Extract â†’ Classify â†’ Script â†’ TTS â†’ Compose â†’ Export â”‚
â”‚  â”‚       â†‘            â†‘         â†‘       â†‘        â†‘          â”‚ â”‚
â”‚  â”‚    PyMuPDF    GPT Vision   GPT-5.2  TTS   MoviePy+FFmpeg â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚   Redis   â”‚  â”‚  File Storage (local)  â”‚   â”‚
â”‚  â”‚(metadata)â”‚  â”‚(jobs/cache)â”‚  â”‚  uploads/ videos/ temp/â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Pipeline Flow

```
PDF â†’ Extract text + images
        â”‚
        â”œâ”€â†’ AI Vision classifies each image (chart/diagram/table/photo/logo)
        â”‚
        â”œâ”€â†’ GPT-5.2 writes scene-by-scene script with layout hints
        â”‚
        â”œâ”€â†’ OpenAI TTS generates voiceover per scene
        â”‚
        â”œâ”€â†’ gpt-image-1 creates AI backgrounds (optional)
        â”‚
        â””â”€â†’ Video Composer assembles everything:
              â€¢ Ken Burns pan/zoom per image type
              â€¢ Split-screen, PiP, carousel layouts
              â€¢ Text overlays, logo watermarks
              â€¢ Crossfade transitions, color grading
              â€¢ GPU export (NVENC) or CPU fallback (libx264)
                    â”‚
                    â–¼
               MP4 Video
```

---

## ğŸ“ Project Structure

```
pdf2video/
â”œâ”€â”€ core/                          # AI video pipeline (standalone)
â”‚   â”œâ”€â”€ pipeline.py                # End-to-end orchestrator
â”‚   â”œâ”€â”€ pdf_extractor.py           # PDF content extraction
â”‚   â”œâ”€â”€ ai_services.py             # OpenAI GPT + TTS + image generation
â”‚   â”œâ”€â”€ image_classifier.py        # AI vision image classification
â”‚   â”œâ”€â”€ video_composer.py          # Video assembly, layouts, export
â”‚   â”œâ”€â”€ effects.py                 # Ken Burns, overlays, transitions
â”‚   â”œâ”€â”€ content_input.py           # Content data structures
â”‚   â””â”€â”€ config.py                  # Centralized settings
â”‚
â”œâ”€â”€ backend/                       # FastAPI server
â”‚   â”œâ”€â”€ main.py                    # App factory, CORS, lifespan
â”‚   â”œâ”€â”€ config.py                  # Pydantic settings
â”‚   â”œâ”€â”€ api/v1/                    # REST endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py                # Register, login, JWT refresh
â”‚   â”‚   â”œâ”€â”€ jobs.py                # Job CRUD + background dispatch
â”‚   â”‚   â”œâ”€â”€ uploads.py             # File upload (PDF, images, music)
â”‚   â”‚   â”œâ”€â”€ videos.py              # Stream, download, delete
â”‚   â”‚   â””â”€â”€ health.py              # Health check + GPU status
â”‚   â”œâ”€â”€ models/                    # SQLAlchemy ORM (User, Job, Video, Upload)
â”‚   â”œâ”€â”€ services/                  # Business logic layer
â”‚   â”œâ”€â”€ workers/                   # Background job workers
â”‚   â””â”€â”€ db/                        # Database session + migrations
â”‚
â”œâ”€â”€ frontend/                      # Next.js 15 app
â”‚   â”œâ”€â”€ src/app/                   # App Router pages
â”‚   â”‚   â”œâ”€â”€ page.tsx               # Dashboard
â”‚   â”‚   â”œâ”€â”€ create/                # Job creation wizard
â”‚   â”‚   â”œâ”€â”€ jobs/                  # Job list + detail + progress
â”‚   â”‚   â”œâ”€â”€ videos/                # Video library + player
â”‚   â”‚   â”œâ”€â”€ login/ & register/     # Authentication
â”‚   â”‚   â””â”€â”€ settings/              # User settings
â”‚   â”œâ”€â”€ src/components/            # UI components (shadcn/ui)
â”‚   â”œâ”€â”€ src/hooks/                 # React hooks (auth, upload, SSE)
â”‚   â”œâ”€â”€ src/stores/                # Zustand state (auth, jobs)
â”‚   â””â”€â”€ src/lib/                   # API client, auth helpers
â”‚
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ docs/ARCHITECTURE_PLAN.md      # Detailed architecture document
```

---

## ğŸ’° API Cost Estimates

Per video (approximate, varies by PDF length):

| Service | Usage | Est. Cost |
|---------|-------|-----------|
| GPT-5.2 | Image classification + script generation | ~$0.05 |
| OpenAI TTS | Narration (~500 words) | ~$0.03 |
| gpt-image-1 | AI backgrounds (2-4 per video) | ~$0.08-0.16 |
| **Total** | | **~$0.16-0.24** |

Disable AI backgrounds in job settings to cut costs roughly in half.

---

## âš™ï¸ Configuration

Key settings in `.env`:

```bash
# Required
OPENAI_API_KEY=sk-your-key-here

# AI Models
OPENAI_CHAT_MODEL=gpt-5.2          # Script generation
OPENAI_TTS_MODEL=tts-1             # Voiceover (tts-1 or tts-1-hd)
OPENAI_TTS_VOICE=onyx              # Default voice
OPENAI_IMAGE_MODEL=gpt-image-1     # AI backgrounds

# Video Output
VIDEO_WIDTH=1920
VIDEO_HEIGHT=1080
VIDEO_FPS=30
VIDEO_BITRATE=12M

# Database
DATABASE_URL=postgresql+asyncpg://pdf2video:password@localhost:5432/pdf2video

# Performance
NUM_WORKERS=8                       # CPU threads for rendering
AUTO_TUNE_WORKERS=true              # Auto-detect optimal thread count
```

### GPU vs CPU

The app auto-detects your hardware:
- **NVIDIA GPU (NVENC)**: Fast encoding, recommended for production
- **CPU (libx264)**: Works on any machine, just slower for the export step

No configuration needed â€” it falls back automatically.

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| NVENC not found | Works fine on CPU â€” this is just informational |
| OPENAI_API_KEY not set | Copy `.env.example` to `.env` and add your key |
| TTS model access denied | Enable TTS models in your OpenAI project settings |
| Slow rendering | Expected on CPU; GPU (NVENC) is ~5-10x faster |
| Database connection error | Ensure PostgreSQL is running and `DATABASE_URL` is correct |
| Frontend can't reach backend | Backend must be running on port 8000 |

---

## ğŸ—ºï¸ Roadmap

- [ ] Preset system (save/load video generation settings)
- [ ] Redis integration for scalable job queue
- [ ] Docker Compose for one-command setup
- [ ] Celery workers for horizontal scaling
- [ ] Video editing / scene-level regeneration
- [ ] Public sharing with signed URLs
- [ ] Batch processing (ZIP of PDFs)
- [ ] Multi-language narration

See [ARCHITECTURE_PLAN.md](docs/ARCHITECTURE_PLAN.md) for the full technical roadmap.

---

## ğŸ“„ License

MIT

---

<div align="center">

Built with [FastAPI](https://fastapi.tiangolo.com) Â· [Next.js](https://nextjs.org) Â· [OpenAI](https://openai.com) Â· [MoviePy](https://zulko.github.io/moviepy/) Â· [shadcn/ui](https://ui.shadcn.com)

</div>
